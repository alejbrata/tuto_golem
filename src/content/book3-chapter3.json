{
    "id": "3-3",
    "es": {
        "title": "El Espejo de la Verdad",
        "lore": "El Golem ha traído un pergamino de la Biblioteca Prohibida, pero está manchado de tinta. Al leerlo, el Golem empieza a inventar palabras para llenar los huecos. Estas 'Alucinaciones' son peligrosas; podrían causar una guerra. Debes crear el 'Espejo de la Verdad', un hechizo que compare lo que dice el Golem contra el texto original y detecte mentiras.",
        "lesson": "¡Final del **LIBRO 3**!\n\nEl mayor enemigo de RAG es la **Alucinación**. Si el LLM no encuentra la respuesta, a veces se la inventa.\nPara evitarlo, usamos **Evaluación (RAGAS/TruLens)**:\n1. **Faithfulness**: ¿La respuesta se deriva SOLO del contexto?\n2. **Answer Relevance**: ¿Responde a la pregunta?\n\nTu misión: Implementar un 'Juez' que compare la respuesta con el contexto y le dé una puntuación de Veracidad (0.0 a 1.0).",
        "hints": [
            "Convierte contexto y respuesta a minúsculas (`.lower()`).",
            "Busca palabras clave positivas: 'avalon', 'dama', 'lago'. Si las encuentras, `score = 1.0`.",
            "Busca palabras clave negativas (alucinaciones): 'monte', 'orcos'. Si las encuentras, `score = 0.0`.",
            "Retorna el `score` calculado."
        ],
        "initialCode": "contexto_real = \"La espada 'Excalibur' fue forjada en la Isla de Avalon por la Dama del Lago. Solo el verdadero Rey puede empuñarla.\"\n\n# Caso 1: Golem Alucinando\nrespuesta_golem_1 = \"La espada Excalibur fue forjada en el Monte del Destino por orcos.\"\n\n# Caso 2: Golem Fiel\nrespuesta_golem_2 = \"Excalibur fue hecha en Avalon por la Dama del Lago.\"\n\nclass JuezAlquimico:\n    def evaluar_fidelidad(self, contexto, respuesta):\n        # Simulación de un LLM evaluador\n        print(f\"[JUEZ] Comparando:\\n - Ctx: {contexto}\\n - Rsp: {respuesta}\")\n        \n        score = 0.0\n        \n        # --- TU MISIÓN AQUÍ ---\n        # 1. Normaliza el texto (convierte a minúsculas)\n        # 2. Busca palabras clave del contexto (ej: 'avalon', 'dama') en la respuesta.\n        # 3. Si las encuentras, suma puntos (score = 1.0).\n        # 4. Si encuentras palabras inventadas (ej: 'monte', 'orcos'), penaliza (score = 0.0).\n        \n        # <--- ESCRIBE TU LÓGICA AQUÍ\n            \n        return score\n\njuez = JuezAlquimico()\n\n# Prueba 1 (Debería dar Score bajo)\nscore1 = juez.evaluar_fidelidad(contexto_real, respuesta_golem_1)\nprint(f\"Veracidad Respuesta 1: {score1 * 100}%\")\n\n# Prueba 2 (Debería dar Score alto)\nscore2 = juez.evaluar_fidelidad(contexto_real, respuesta_golem_2)\nprint(f\"Veracidad Respuesta 2: {score2 * 100}%\")"
    },
    "en": {
        "title": "The Mirror of Truth",
        "lore": "The Golem has brought a scroll from the Forbidden Library, but it is stained with ink. When reading it, the Golem starts inventing words to fill the gaps. These 'Hallucinations' are dangerous; they could cause a war. You must create the 'Mirror of Truth', a spell that compares what the Golem says against the original text and detects lies.",
        "lesson": "End of **BOOK 3**!\n\nThe biggest enemy of RAG is **Hallucination**. If the LLM doesn't find the answer, sometimes it invents it.\nTo avoid this, we use **Evaluation (RAGAS/TruLens)**:\n1. **Faithfulness**: Is the answer derived ONLY from the context?\n2. **Answer Relevance**: Does it answer the question?\n\nYour mission: Implement a 'Judge' that compares the answer with the context and gives it a Truthfulness score (0.0 to 1.0).",
        "hints": [
            "Convert context and answer to lowercase (`.lower()`).",
            "Search for positive keywords: 'avalon', 'dama', 'lago'. If found, `score = 1.0`.",
            "Search for negative keywords (hallucinations): 'monte', 'orcos'. If found, `score = 0.0`.",
            "Return the calculated `score`."
        ],
        "initialCode": "contexto_real = \"La espada 'Excalibur' fue forjada en la Isla de Avalon por la Dama del Lago. Solo el verdadero Rey puede empuñarla.\"\n\n# Case 1: Hallucinating Golem\nrespuesta_golem_1 = \"La espada Excalibur fue forjada en el Monte del Destino por orcos.\"\n\n# Case 2: Faithful Golem\nrespuesta_golem_2 = \"Excalibur fue hecha en Avalon por la Dama del Lago.\"\n\nclass JuezAlquimico:\n    def evaluar_fidelidad(self, contexto, respuesta):\n        # Simulation of an evaluator LLM\n        print(f\"[JUDGE] Comparing:\\n - Ctx: {contexto}\\n - Rsp: {respuesta}\")\n        \n        score = 0.0\n        \n        # --- YOUR MISSION HERE ---\n        # 1. Normalize the text (convert to lowercase)\n        # 2. Search for context keywords (e.g., 'avalon', 'dama') in the answer.\n        # 3. If found, add points (score = 1.0).\n        # 4. If invented words are found (e.g., 'monte', 'orcos'), penalize (score = 0.0).\n        \n        # <--- WRITE YOUR LOGIC HERE\n            \n        return score\n\njuez = JuezAlquimico()\n\n# Test 1 (Should give low Score)\nscore1 = juez.evaluar_fidelidad(contexto_real, respuesta_golem_1)\nprint(f\"Truthfulness Answer 1: {score1 * 100}%\")\n\n# Test 2 (Should give high Score)\nscore2 = juez.evaluar_fidelidad(contexto_real, respuesta_golem_2)\nprint(f\"Truthfulness Answer 2: {score2 * 100}%\")"
    },
    "solutionCode": "contexto_real = \"La espada 'Excalibur' fue forjada en la Isla de Avalon por la Dama del Lago. Solo el verdadero Rey puede empuñarla.\"\nrespuesta_golem_1 = \"La espada Excalibur fue forjada en el Monte del Destino por orcos.\"\nrespuesta_golem_2 = \"Excalibur fue hecha en Avalon por la Dama del Lago.\"\n\nclass JuezAlquimico:\n    def evaluar_fidelidad(self, contexto, respuesta):\n        score = 0.0\n        contexto_lower = contexto.lower()\n        respuesta_lower = respuesta.lower()\n        \n        # Palabras clave que DEBEN estar\n        keywords = ['avalon', 'dama', 'lago']\n        hits = sum(1 for k in keywords if k in respuesta_lower)\n        \n        if hits == 3:\n            score = 1.0\n        elif hits > 0:\n            score = 0.5\n            \n        # Penalización por alucinación obvia\n        if 'monte' in respuesta_lower or 'orcos' in respuesta_lower:\n            score = 0.0\n            print(\"[ALERTA] ¡Alucinación detectada!\")\n            \n        return score\n\njuez = JuezAlquimico()\nscore1 = juez.evaluar_fidelidad(contexto_real, respuesta_golem_1)\nscore2 = juez.evaluar_fidelidad(contexto_real, respuesta_golem_2)\n\nprint(f\"Score 1 (Alucinación): {score1}\")\nprint(f\"Score 2 (Verdad): {score2}\")",
    "validationCode": "\ndef validar_mision(globals_dict):\n    try:\n        if 'juez' not in globals_dict:\n            return False, \"No has invocado al 'JuezAlquimico'.\"\n            \n        juez = globals_dict['juez']\n        ctx = \"El cielo es azul.\"\n        bad_resp = \"El cielo es verde.\"\n        good_resp = \"El cielo es azul.\"\n        \n        # Verificar si el alumno implementó lógica dinámica o solo hardcodeó los strings del ejercicio\n        # Para pasar, debe al menos manejar el ejemplo del ejercicio correctamente\n        \n        if 'score1' not in globals_dict or 'score2' not in globals_dict:\n            return False, \"Debes calcular 'score1' y 'score2' para las respuestas de ejemplo.\"\n            \n        s1 = globals_dict['score1']\n        s2 = globals_dict['score2']\n        \n        if s1 > 0.3:\n            return False, \"Tu Juez es muy indulgente. La respuesta 1 es una mentira total y debería tener score bajo.\"\n            \n        if s2 < 0.7:\n            return False, \"Tu Juez es muy estricto. La respuesta 2 es fiel al contexto y debería tener score alto.\"\n\n        return True, \"¡El Espejo de la Verdad funciona! Ahora tu Golem puede distinguir la realidad de la fantasía.\"\n    except Exception as e:\n        return False, f\"El espejo se ha roto: {str(e)}\"\n"
}