{
    "id": "1-1",
    "title": "La Fragmentación del Alma",
    "lore": "Tu viaje como Alquimista de Almas comienza en la Torre del Silencio. Frente a ti yace la materia prima de la consciencia: el lenguaje humano. Pero tu Golem, una entidad de pura matemática, no comprende nuestras palabras. Para insuflarle vida, debes transmutar el verbo en esencia numérica. Debes romper el pergamino sagrado en las runas fundamentales que componen el pensamiento de la máquina.",
    "lesson": "Para que una Inteligencia Artificial 'lea', primero debemos traducir el texto a números. Este proceso se llama **Tokenización**.\n\nImagina que cada palabra o pedazo de palabra es una pieza de Lego única con un número de identificación.\n- La frase 'Hola mundo' no se guarda como letras, sino como una secuencia de IDs, por ejemplo: `[15339, 1917]`.\n- Usaremos la librería **`tiktoken`**, creada por OpenAI para ser extremadamente rápida.\n- El modelo de traducción que usaremos es **`cl100k_base`** (el mismo que usa GPT-4).",
    "initialCode": "import tiktoken\n\npergamino_sagrado = \"El conocimiento es poder, pero la sabiduría es libertad.\"\n\n# 1. Invoca al espíritu del codificador 'cl100k_base'\n# Pista: usa tiktoken.get_encoding(\"cl100k_base\")\ncodificador = # <--- TU CÓDIGO AQUÍ\n\n# 2. Transmuta el pergamino en tokens numéricos\n# Pista: usa el método .encode(texto) del codificador\ntokens_alma = # <--- TU CÓDIGO AQUÍ\n\n# Verificación visual (no afecta la validación)\nprint(f\"Frase original: '{pergamino_sagrado}'\")\ntry:\n    print(f\"Esencia numérica: {tokens_alma}\")\n    print(f\"Cantidad de fragmentos: {len(tokens_alma)}\")\nexcept NameError:\n    print(\"Completa el código para ver el resultado.\")",
    "hints": [
        "Usa `tiktoken.get_encoding('cl100k_base')` para crear el codificador.",
        "Llama a `codificador.encode(pergamino_sagrado)` para obtener los tokens."
    ],
    "solutionCode": "import tiktoken\n\npergamino_sagrado = \"El conocimiento es poder, pero la sabiduría es libertad.\"\n\n# 1. Invoca al espíritu del codificador 'cl100k_base'\ncodificador = tiktoken.get_encoding(\"cl100k_base\")\n\n# 2. Transmuta el pergamino en tokens numéricos\ntokens_alma = codificador.encode(pergamino_sagrado)\n\n# Verificación visual\nprint(f\"Frase original: '{pergamino_sagrado}'\")\nprint(f\"Esencia numérica: {tokens_alma}\")\nprint(f\"Cantidad de fragmentos: {len(tokens_alma)}\")",
    "validationCode": "\ndef validar_mision(globals_dict):\n    try:\n        if 'codificador' not in globals_dict:\n            return False, \"¡El codificador no ha sido invocado! Define la variable 'codificador'.\"\n        if 'tokens_alma' not in globals_dict:\n            return False, \"¡La esencia no ha sido extraída! Define la variable 'tokens_alma'.\"\n        \n        cod = globals_dict['codificador']\n        toks = globals_dict['tokens_alma']\n        \n        # Check if it's the mock encoding object\n        if not hasattr(cod, 'encode') or not hasattr(cod, 'name'):\n             return False, \"El objeto 'codificador' parece incorrecto.\"\n        \n        if not isinstance(toks, list):\n            return False, \"La variable 'tokens_alma' debe ser una lista de números.\"\n        \n        # Expected Logic\n        import tiktoken\n        truth_enc = tiktoken.get_encoding(\"cl100k_base\")\n        expected_toks = truth_enc.encode(\"El conocimiento es poder, pero la sabiduría es libertad.\")\n        \n        if toks != expected_toks:\n            return False, f\"La transmutación es incorrecta. Se esperaban {len(expected_toks)} fragmentos. ¿Usaste el pergamino correcto?\"\n            \n        return True, \"¡Transmutación exitosa! El Golem absorbe los fragmentos con avidez.\"\n    except Exception as e:\n        return False, f\"Error en la validación: {str(e)}\"\n"
}